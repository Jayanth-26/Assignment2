# -*- coding: utf-8 -*-
"""PDS_Assignmemt2_Jay.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RzsCpueZsXCBKfHEeXebwY6_XatV1CYc

## Loading the dataset
"""

import pandas as pd

# Load your dataset
df = pd.read_csv("/content/train.csv")
df.head()

"""## a)handling missing values"""

# Drop 'New_Price' if >80% missing
if 'New_Price' in df.columns and df['New_Price'].isnull().mean() > 0.8:
    df.drop(columns=['New_Price'], inplace=True)

# Impute missing values
for col in df.columns:
    if df[col].isnull().sum() > 0:
        if df[col].dtype in ['float64', 'int64']:
            df[col] = df[col].fillna(df[col].median())
        else:
            df[col] = df[col].fillna(df[col].mode()[0])

# Display first 10 rows
print(df.head().to_string(index=False))

"""## Justification for Data Cleaning and Preprocessing
Due to its over 80% missing values, the New_Price field was removed since it was not appropriate for trustworthy imputation or analysis.

To reduce the impact of outliers and maintain central tendency, missing values in numerical features (such Seats, Power, or Engine) for the remaining columns were imputed using the median.

The mode was used to impute missing values in categorical columns (like Owner_Type), making sure that the most common category was selected to preserve logical consistency.

This approach guarantees that the dataset is as clean and consistent as feasible for subsequent analysis, while simultaneously preserving as much useful information as possible.

## b)removing units from columns
"""

# Define function to extract numeric part
def extract_number(x):
    if pd.isnull(x):
        return np.nan
    return float(str(x).split()[0].replace(',', ''))

# Clean columns if they exist
if 'Mileage' in df.columns:
    df['Mileage'] = df['Mileage'].apply(extract_number)

if 'Engine' in df.columns:
    df['Engine'] = df['Engine'].apply(extract_number)

if 'Power' in df.columns:
    df['Power'] = df['Power'].apply(lambda x: extract_number(str(x).replace('bhp', '')))

if 'New_Price' in df.columns:
    df['New_Price'] = df['New_Price'].astype(str).str.replace('Lakh', '', regex=False)
    df['New_Price'] = df['New_Price'].apply(lambda x: float(x) if x.replace('.', '', 1).isdigit() else np.nan)

# Display first 5 rows of the full dataset in original format with cleaned values
print(df.head().to_string(index=False))

"""## c)one hot encode fueltype and transmission"""

df_encoded = pd.get_dummies(df, columns=['Fuel_Type', 'Transmission'], drop_first=False)

# Convert any boolean columns to integers (0/1), just in case
for col in df_encoded.columns:
    if df_encoded[col].dtype == bool:
        df_encoded[col] = df_encoded[col].astype(int)

# Display first 5 rows of the encoded columns only
encoded_columns = [col for col in df_encoded.columns if 'Fuel_Type_' in col or 'Transmission_' in col]
print(df_encoded[encoded_columns].head(5).to_string(index=False))

"""## d) Creating new feature-car age"""

from datetime import datetime
current_year = datetime.now().year
df['Car_Age'] = current_year - df['Year']
#print(df['Car_Age'])
print(df[['Name', 'Year', 'Car_Age']].head())

"""## e) Performing select,filter,rename,mutate,arrange,summarize operations"""

# Split Name into Make and Model (fix applied)
df[['Make', 'Model']] = df['Name'].str.split(' ', n=1, expand=True)


# Identify encoded columns for Fuel and Transmission
encoded_fuel = [col for col in df.columns if 'Fuel_Type' in col]
encoded_trans = [col for col in df.columns if 'Transmission' in col]

# Select relevant columns
selected_cols = ['Make', 'Model', 'Price', 'Car_Age'] + encoded_fuel + encoded_trans
selected_df = df[selected_cols]

# Filter cars older than 10 years and price > 5 lakh
filtered_df = selected_df[(df['Car_Age'] > 10) & (df['Price'] > 5)]

# Rename 'Price' to 'Used_Price'
renamed_df = filtered_df.rename(columns={'Price': 'Used_Price'})

# Add new column: Price per Year
renamed_df['Price_per_Year'] = renamed_df['Used_Price'] / renamed_df['Car_Age']

# Arrange by price descending
arranged_df = renamed_df.sort_values(by='Used_Price', ascending=False)

# Summarize: group by Make
summary = df.groupby('Make').agg(
    Avg_Price=('Price', 'mean'),
    Count=('Price', 'count')
).reset_index()

# Display sample outputs
print("Top 5 sorted cars:\n", arranged_df.head())
print("\nGrouped Summary by Make:\n", summary.head())